{"cells":[{"cell_type":"markdown","metadata":{"id":"9yTACQsd97iF"},"source":["# SET MODE:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1l5Z1Xx3-Chy"},"outputs":[],"source":["SCORING = False                     #Choose True or False\n","REPRESENTATION = \"tf_idf\"           #Choose from [\"tf_idf\", \"non_cont_word_emb\", \"bart_tokenized\"]\n","BART_EMB_TYPE = None                #Select only if REPRESENTATION = \"bart_tokenized\"! Choose \"word\" for average word embedding or \"doc\" for <EOS> Embedding"]},{"cell_type":"markdown","metadata":{"id":"S42HwQXq-Aio"},"source":["# Imports"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5550,"status":"ok","timestamp":1653519164315,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"},"user_tz":-120},"id":"cLbST2_TOqOE"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import pickle5 as pickle\n","from collections import defaultdict\n","from torch.optim import AdamW\n","import itertools\n","import numpy as np\n","from tqdm import tqdm\n","from transformers import BartModel\n","import random\n","from scipy import sparse"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1653519164316,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"},"user_tz":-120},"id":"9_7-E9WvZQIv"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"C8hInpVok8hk"},"source":["## BART Helper"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1653519164316,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"},"user_tz":-120},"id":"KWr6a_nHk_HJ"},"outputs":[],"source":["def get_bart_embeddings(batch, embedding_type, bart):\n","    with torch.no_grad():\n","        input_ids = batch[:,0].to(device)\n","        attention_mask = batch[:,1].to(device)\n","        \n","        doc_embeds = bart(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n","\n","        if embedding_type == \"doc\":\n","            eos_positions = torch.sum(attention_mask, dim=-1).unsqueeze(-1)\n","            eos_positions = eos_positions - 1\n","            dummy = eos_positions.unsqueeze(2).expand(eos_positions.size(0), eos_positions.size(1), doc_embeds.size(2))\n","            eos_embeds= torch.gather(doc_embeds, 1, dummy)\n","            return eos_embeds.squeeze(1)\n","        \n","        elif embedding_type == \"word\":\n","            return torch.mean(doc_embeds, dim=1)"]},{"cell_type":"markdown","metadata":{"id":"dDpjjycfgG1Q"},"source":["## Score Helpers"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1653519164316,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"},"user_tz":-120},"id":"byj2awLvvuza"},"outputs":[],"source":["from scipy.sparse import csr_matrix\n","def pack_csrs(unpacked_data):\n","    data = []\n","    for dp in unpacked_data:\n","        data.append([\n","            dp[0], \n","            dp[1], \n","            csr_matrix(*dp[2]),\n","            csr_matrix(*dp[3]),\n","            dp[-1]])\n","    return data\n","\n","def unpack_csrs(data):\n","    unpacked_data = []\n","    for dp in data:\n","        unpacked_data.append([\n","            dp[0], \n","            dp[1], \n","            ((dp[2].data, dp[2].indices, dp[2].indptr), dp[2].shape),\n","            ((dp[3].data, dp[3].indices, dp[3].indptr), dp[3].shape),\n","            dp[-1]])\n","    return unpacked_data"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1653519164317,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"},"user_tz":-120},"id":"zxKMm90-vTH_"},"outputs":[],"source":["from operator import pos\n","def get_avg_doc_len(bows):\n","    bows = sparse.vstack([bow[3] for bow in bows])\n","    counts = bows.sum(axis=-1)\n","    avg = counts.mean()\n","    return avg\n","\n","def get_bim_weights(bows):\n","    N = len(set([bow[1] for bow in bows]))\n","    pos_docs = sparse.vstack([bow[3] for bow in bows if bool(bow[-1]) is True])\n","    pos_counts = pos_docs.sum(axis=0).getA().squeeze()\n","    bim_weights = np.log(((N - pos_counts + 0.5)/(pos_counts + 0.5)) + 1)\n","    return bim_weights\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":91422,"status":"ok","timestamp":1653519255734,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"},"user_tz":-120},"id":"kk6_WIM6ghO-"},"outputs":[],"source":["#Load Bag of Word representations and calculate weights for BM25\n","bows = pack_csrs(pickle.load(open(\"data/train_count_vector_unpacked.pickle\", \"rb\")))\n","AVG_DOC_LEN = get_avg_doc_len(bows)\n","BIM_WEIGHTS = get_bim_weights(bows)\n","del bows\n","\n","#Load pretrained Logistic Regression model\n","if REPRESENTATION == \"tf_idf\":\n","    LOGREG = pickle.load(open(\"./models/LR_tfidf_fit.pickle\", \"rb\" ))\n","else:\n","    LOGREG = pickle.load(open(\"./models/LR_emb_fit.pickle\", \"rb\" ))\n"]},{"cell_type":"markdown","metadata":{"id":"l50Gugsz_bKc"},"source":["## Scoring Functions"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1653519255734,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"},"user_tz":-120},"id":"N8K25dX_gGZn"},"outputs":[],"source":["def compute_bm25(query_vec, doc_vec, k=1.5, b=0.75):\n","    non_zero = [ np.nonzero(t)[0] if np.nonzero(t).size()[0] > 0 else -1 for t in query_vec ] #indices of words occuring in the query\n","    relevances = []\n","    for i, q in enumerate(non_zero):\n","        if q == -1:\n","            relevances.append(0)\n","            continue\n","        doc = doc_vec[i]\n","        counts = doc[q]\n","        weights = BIM_WEIGHTS[q]\n","        doc_len = doc.sum()\n","        frac = (counts * (k+1))/(counts + k*(doc_len/AVG_DOC_LEN)*b + k*(1-b))\n","        relevances.append(torch.sum(frac*weights, -1))\n","    return torch.tensor(np.vstack(relevances))\n","    \n","def get_batch_LR_proba(query_vecs, doc_vecs, logreg):\n","    '''Input : \n","    query_vecs, doc_vecs : tfidf vectors of query and doc (2D array)\n","    logreg : fitted logistic regression\n","\n","    Output : array of probabilites returned by LR'''\n","    \n","    if query_vecs.size() != doc_vecs.size():\n","        raise ValueError('Arrays are not of the same size')\n","    X = torch.concat((query_vecs, doc_vecs), dim=1)\n","    y_scores = logreg.predict_proba(X)\n","    LR_results = y_scores[:,0]\n","    return torch.tensor(LR_results)\n","\n","def compute_cosine_similarity(query_vec, doc_vec):\n","    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","    return cos(query_vec, doc_vec)\n","\n","\n","def compute_jaccard_similarity(query_vec, doc_vec):\n","    query_vec = torch.where(query_vec > 0, 1.0, 0.0)\n","    doc_vec = torch.where(doc_vec > 0, 1.0, 0.0)\n","\n","    intersect = query_vec * doc_vec\n","    union = torch.clamp(query_vec + doc_vec, 0.0, 1.0)    \n","    result = torch.sum(intersect, dim=1) / torch.sum(union, dim=1)\n","    return torch.nan_to_num(result, nan=0.0) #Fix Nulldivision"]},{"cell_type":"markdown","metadata":{"id":"Mbg2jVlUoDbQ"},"source":["## NN Model"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1653519255735,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"},"user_tz":-120},"id":"NugGOGnSOwmP"},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self, input_size, scoring):\n","        super(Net, self).__init__()\n","        if scoring:\n","            self.fc1 = nn.Linear(input_size, 16) \n","            self.fc2 = nn.Linear(16, 8)\n","            self.fc3 = nn.Linear(8, 8)\n","            self.fc4 = nn.Linear(8, 1)\n","        else:\n","            self.fc1 = nn.Linear(input_size, 256) \n","            self.fc2 = nn.Linear(256, 64)\n","            self.fc3 = nn.Linear(64, 32)\n","            self.fc4 = nn.Linear(32, 1)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = F.relu(self.fc3(x))\n","        x = self.fc4(x)\n","        \n","        return x"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":775,"status":"ok","timestamp":1653562285344,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"},"user_tz":-120},"id":"h1dVjaT3Oyt6"},"outputs":[],"source":["def visualize_net():\n","    \"\"\"get pretty picture of gradient flow\"\"\"\n","    from torchviz import make_dot\n","    x=torch.ones(10, requires_grad=True)\n","    net = Net(10)\n","    pred = net(x)\n","    make_dot(pred, params=dict(list(net.named_parameters()))).render(\"nn\", format=\"png\")"]},{"cell_type":"markdown","metadata":{"id":"HqI1T6KZoJ8q"},"source":["## Load the data: Representations"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":484,"status":"ok","timestamp":1653519256213,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"},"user_tz":-120},"id":"WMht67NEO3wu"},"outputs":[],"source":["class PointwiseDataset(Dataset):\n","    #for the clear representation based \n","    def __init__(self, filename, bows_filename=None):\n","        self.data = pickle.load(open(filename, \"rb\" ))\n","        self.data = [list(elem) for elem in self.data]\n","\n","        #Fix empty entries resulting form empty queries/docs\n","        for i in range(len(self.data)):\n","            if type(self.data[i][2]) is float:               \n","                self.data[i][2] = np.zeros(self.data[0][2].size)                \n","            if type(self.data[i][3]) is float:               \n","                self.data[i][3] = np.zeros(self.data[0][3].size)\n","\n","        #Try with less data for bart:\n","        #random.shuffle(self.data)\n","        #self.data = self.data[:int(0.65 * len(self.data))]\n","\n","        self.bows = None\n","        if bows_filename:\n","            self.bows = pack_csrs(pickle.load(open(bows_filename, \"rb\" )))\n","\n","\n","\n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, idx):\n","        ids = self.data[idx][0:2]\n","        label = self.data[idx][-1]\n","        representations = self.data[idx][2:4]\n","        representations = [np.array(item) for item in representations]\n","\n","        if self.bows:            \n","            #Add BOW for Jaccard and BM25:\n","            representations.extend([self.bows[idx][2].toarray().squeeze(), self.bows[idx][3].toarray().squeeze()])\n","\n","        return ids, representations, label"]},{"cell_type":"markdown","metadata":{"id":"EWQbrKnbocQ7"},"source":["## Training"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2519,"status":"ok","timestamp":1653519258731,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"},"user_tz":-120},"id":"ljR7VlilG8jl"},"outputs":[],"source":["def train(representation, scoring, epochs=2, batch_size=16, bart_emb_type=None):\n","    \"\"\"Gets as input the representation name (e.g. \"tf_idf\")\"\"\"\n","    if scoring:\n","        train_dataset = PointwiseDataset(filename = f\"data/train_{representation}.pickle\", bows_filename=f\"data/train_count_vector_unpacked.pickle\")\n","        dev_dataset = PointwiseDataset(f\"data/dev_{representation}.pickle\", bows_filename=f\"data/dev_count_vector_unpacked.pickle\")\n","        if bart_emb_type:\n","            vector_size = 3 \n","        else:\n","            vector_size = 4\n","\n","    else:\n","        train_dataset = PointwiseDataset(filename = f\"data/train_{representation}.pickle\")\n","        dev_dataset = PointwiseDataset(f\"data/dev_{representation}.pickle\")\n","        if bart_emb_type:\n","            vector_size = 768 * 2 #Bart Embedding size (times two because of concatenation)\n","        else:\n","            vector_size = train_dataset.data[0][3].shape[-1] * 2 #Get size of representations#\n","        \n","\n","    if bart_emb_type:\n","        bart = BartModel.from_pretrained(\"facebook/bart-base\").to(device)\n","        bart.eval()\n","\n","    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    dev_dataloader = DataLoader(dev_dataset, batch_size=batch_size)\n","    \n","    net = Net(vector_size, scoring).to(device)\n","\n","    criterion = nn.BCEWithLogitsLoss() #Binary Cross Entropy Loss\n","    optimizer = AdamW(net.parameters())\n","\n","    for epoch in range(epochs):\n","        net.train()\n","        running_loss = 0.0\n","        for i, data in enumerate(tqdm(train_dataloader)):\n","            ids, reps, labels = data\n","\n","            if bart_emb_type:\n","                reps[0] = get_bart_embeddings(reps[0], bart_emb_type, bart)\n","                reps[1] = get_bart_embeddings(reps[1], bart_emb_type, bart)\n","\n","            if scoring:\n","                cosine = compute_cosine_similarity(reps[0], reps[1]).unsqueeze(-1).to(device)  \n","                jacc = compute_jaccard_similarity(reps[2], reps[3]).unsqueeze(-1).to(device)  \n","                bm25 = compute_bm25(reps[2], reps[3]).to(device)\n","                if not bart_emb_type:\n","                    log_prob = get_batch_LR_proba(reps[0], reps[1], LOGREG).unsqueeze(-1)  \n","                    inputs = torch.concat((cosine, jacc, bm25, log_prob), dim=1).to(device)\n","                else:\n","                    inputs = torch.concat((cosine, jacc, bm25), dim=1).to(device)\n","\n","            else:\n","                if bart_emb_type:\n","                    repr1 = reps[0] #already tensor\n","                    repr2 = reps[1]\n","                else:\n","                    repr1 = torch.tensor(reps[0]).to(device)\n","                    repr2 = torch.tensor(reps[1]).to(device)\n","                inputs = torch.concat((repr1, repr2), dim=1)\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            outputs = net(inputs.float())\n","            loss = criterion(outputs, labels.float().to(device))\n","            loss.backward()\n","            optimizer.step()\n","\n","            # print statistics\n","            running_loss += loss.item()\n","            if i % 100 == 1 and i > 100:\n","                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n","                running_loss = 0.0\n","        \n","        if scoring:\n","            torch.save(net.state_dict(), f=f'./models/checkpoints/{representation}_word_pointwise_scoring_{epoch}.model')\n","        else:\n","            torch.save(net.state_dict(), f=f'./models/checkpoints/{representation}_pointwise_{epoch}.model')\n","        \n","        #Evaluate  \n","        with torch.no_grad():\n","            net.eval()\n","            eval_loss = 0.0\n","            for i, data in enumerate(dev_dataloader):\n","                ids, reps, labels = data\n","                if scoring:\n","                    cosine = compute_cosine_similarity(reps[0], reps[1]).unsqueeze(-1)  \n","                    jacc = compute_jaccard_similarity(reps[2], reps[3]).unsqueeze(-1)  \n","                    bm25 = compute_bm25(reps[2], reps[3])\n","                    if not bart_emb_type:\n","                        log_prob = get_batch_LR_proba(reps[0], reps[1], LOGREG).unsqueeze(-1)  \n","                        inputs = torch.concat((cosine, jacc, bm25, log_prob), dim=1).to(device)\n","                    else:\n","                        inputs = torch.concat((cosine, jacc, bm25), dim=1).to(device)\n","                else:\n","                    repr1 = torch.tensor(reps[0]).to(device)\n","                    repr2 = torch.tensor(reps[1]).to(device)\n","                    inputs = torch.concat((repr1, repr2), dim=1)              \n","\n","                outputs = net(inputs.float())\n","                loss = criterion(outputs, labels.float().to(device))\n","                eval_loss += loss.item()\n","            \n","            print(f'Epoch {epoch + 1} dev loss: {eval_loss / len(dev_dataloader)}')            \n","        \n","    if scoring:\n","        torch.save(net.state_dict(), f=f'./models/{representation}_pointwise_scoring.model')\n","    else:\n","        torch.save(net.state_dict(), f=f'./models/{representation}_pointwise.model')\n","   \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KyjUpvUmYeol"},"outputs":[],"source":["train(REPRESENTATION, SCORING, epochs=2, batch_size=120, bart_emb_type=BART_EMB_TYPE)"]},{"cell_type":"markdown","metadata":{"id":"IMbYJ3w5oemi"},"source":["## Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ivV4_mjlO7_O"},"outputs":[],"source":["def test(representation, scoring, batch_size, bart_emb_type=None):\n","    \"\"\"Gets as input the representation name (e.g. \"tf_idf\")\"\"\"\n","    \n","    \n","    if scoring:\n","        test_dataset = PointwiseDataset(filename = f\"./data/test_{representation}.pickle\", bows_filename=f\"./data/test_count_vector_unpacked.pickle\")\n","        if bart_emb_type:\n","            vector_size = 3 \n","        else:\n","            vector_size = 4\n","        model_file=f'./models/{representation}_pointwise_scoring.model'\n","\n","    else:\n","        test_dataset = PointwiseDataset(filename = f\"./data/test_{representation}.pickle\")\n","        if bart_emb_type:\n","            vector_size = 768 * 2 #Chosen Bart Embedding size        \n","        else:\n","            vector_size = test_dataset.data[0][3].shape[-1]  * 2  #Get size of representations\n","        model_file=f'./models/checkpoints/{representation}_pointwise.model'\n","\n","\n","    if bart_emb_type:\n","        bart = BartModel.from_pretrained(\"facebook/bart-base\").to(device)\n","\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n","    net = Net(vector_size, scoring).to(device)\n","    net.load_state_dict(torch.load(model_file))\n","\n","    #Save here the (queryID, docID), labels and model_score for evaluation\n","    query_ids = []\n","    doc_ids = []\n","    scores = []\n","\n","    with torch.no_grad():\n","        net.eval()\n","        eval_loss = 0.0\n","        for i, data in enumerate(tqdm(test_dataloader)):\n","            ids, reps, labels = data\n","\n","            if bart_emb_type:\n","                reps[0] = get_bart_embeddings(reps[0], bart_emb_type, bart)\n","                reps[1] = get_bart_embeddings(reps[1], bart_emb_type, bart)\n","\n","            if scoring:\n","                cosine = compute_cosine_similarity(reps[0], reps[1]).unsqueeze(-1).to(device)  \n","                jacc = compute_jaccard_similarity(reps[2], reps[3]).unsqueeze(-1).to(device)  \n","                bm25 = compute_bm25(reps[2], reps[3]).to(device)\n","                if not bart_emb_type:\n","                    log_prob = get_batch_LR_proba(reps[0], reps[1], LOGREG).unsqueeze(-1).to(device)  \n","                    inputs = torch.concat((cosine, jacc, bm25, log_prob), dim=1).to(device)\n","                else:\n","                    inputs = torch.concat((cosine, jacc, bm25), dim=1).to(device)\n","            else:\n","                if bart_emb_type:\n","                    repr1 = reps[0] #already tensor\n","                    repr2 = reps[1]\n","                else:\n","                    repr1 = torch.tensor(reps[0]).to(device)\n","                    repr2 = torch.tensor(reps[1]).to(device)\n","                inputs = torch.concat((repr1, repr2), dim=1)            \n","\n","            outputs = net(inputs.float())\n","            outputs = outputs.cpu().numpy()\n","            \n","            scores.extend(outputs.squeeze().tolist())\n","            query_ids.extend(list(ids[:][0]))\n","            doc_ids.extend(list(ids[:][1]))\n","\n","    test_outputs = defaultdict(list)\n","    for i in range(len(query_ids)):\n","        test_outputs[query_ids[i]].append((doc_ids[i], scores[i]))\n","\n","    if scoring:\n","        filename = f'model_predictions/{representation}_pointwise_scoring_preds.pickle'\n","    else:\n","        filename = f'model_predictions/{representation}_pointwise_preds.pickle'\n","    with open(filename, 'wb') as handle:\n","        pickle.dump(test_outputs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":826226,"status":"ok","timestamp":1653515031252,"user":{"displayName":"Anna Eschbach-Dymanus","userId":"15135727199976857319"},"user_tz":-120},"id":"Lq9vFF2dJIdp","outputId":"229d974d-3531-4e39-df90-b9b1bfa28500"},"outputs":[],"source":["test(REPRESENTATION, SCORING, epochs=2, batch_size=120, bart_emb_type=BART_EMB_TYPE)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOHAHihQVdulrfwxRxZXY0L","collapsed_sections":[],"machine_shape":"hm","name":"PointwNN.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
