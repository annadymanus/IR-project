{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a878cb1-00e6-46cf-945b-d5370330849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "t = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa773d94-31df-43dc-9b41-30fe6d02e436",
   "metadata": {},
   "source": [
    "## Creating the LR pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26071647-91bf-4a0f-bb9e-30a8e4e441fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(filename: str): \n",
    "    '''Read pickle to get the info'''\n",
    "    list_pickle =  pickle.load(open(filename,\"rb\"))\n",
    "    return list_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52862fde-e0b6-40bb-af1e-5ec8a8ef22a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume that we have train_tf_idf.pickle and test_tf_idf in folder\n",
    "train_tf_idf = read_pickle('train_tf_idf.pickle')\n",
    "test_tf_idf = read_pickle('test_tf_idf.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68ed0e54-b157-4cc4-96fe-ce38a9d3f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_vectors(batch):\n",
    "    '''Input : batch\n",
    "    Output : Array of vectors'''\n",
    "    X = []\n",
    "    for i in range(len(batch)):\n",
    "        X.append(np.concatenate((batch[i][2], batch[i][3])))\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c48a7e51-5c44-4058-b9e0-f47ef0abbfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_vector(batch): \n",
    "    '''Input : batch\n",
    "    Output : array of integers (0 or 1)'''\n",
    "    list_bool = [list(elem[4]) for elem in batch]\n",
    "    preprocessed_list_bool = []\n",
    "    for boolean in list_bool:\n",
    "        if boolean == [False]:\n",
    "            preprocessed_list_bool.append(0)\n",
    "        else:\n",
    "            preprocessed_list_bool.append(1)\n",
    "    return np.array(preprocessed_list_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88ba469d-a6c1-4cde-882e-94e08da7cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = get_X_vectors(train_tf_idf)\n",
    "y_train = get_y_vector(train_tf_idf)\n",
    "\n",
    "X_test = get_X_vectors(test_tf_idf)\n",
    "y_test = get_y_vector(test_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d2037a0-365f-4743-9259-40328d381af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty='l1', C=1.0, solver='liblinear')\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d87e9413-83d5-4834-946e-bff20df68d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open('LR_model_fit.pickle', 'wb')\n",
    "pickle.dump(logreg, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5ef2c3-26d2-4e9b-9bb3-b7c7a20552b3",
   "metadata": {},
   "source": [
    "## Defining a function that takes vectors in entry and return LR probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e50b6dd4-4dbf-4e17-a44e-806bfad9b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_LR_proba(query_vecs, doc_vecs, logreg):\n",
    "    '''Input : \n",
    "    query_vecs, doc_vecs : tfidf vectors of query and doc (2D array)\n",
    "    logreg : fitted logistic regression\n",
    "    Output : array of probabilites returned by LR'''\n",
    "    if len(query_vecs)!=len(doc_vecs):\n",
    "        raise ValueError('Arrays are not of the same size')\n",
    "    X = []\n",
    "    for i in range(len(query_vecs)):\n",
    "        X.append(np.concatenate((query_vecs[i], doc_vecs[i])))\n",
    "    y_scores = logreg.predict_proba(X)\n",
    "    LR_results = [y_scores[i,0] for i in range(len(y_scores))]\n",
    "    return np.array(LR_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "247cf8b4-f612-4709-9987-b5cc46200108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37057483, 0.38482529, 0.491763  , 0.46707768, 0.44896146,\n",
       "       0.66988109, 0.46134323, 0.36765006, 0.43042553, 0.73689352])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the function\n",
    "query_vecs_list = [train_tf_idf[i][2] for i in range(10)]\n",
    "query_vecs = np.array(query_vecs_list)\n",
    "doc_vecs_list = [train_tf_idf[i][3] for i in range(10)]\n",
    "doc_vecs = np.array(doc_vecs_list)\n",
    "get_batch_LR_proba(query_vecs, doc_vecs, logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ddab85c-a360-4154-8c45-a5d628e97005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time : 00:01:01\n"
     ]
    }
   ],
   "source": [
    "print(f\"Execution time : {time.strftime('%H:%M:%S', time.gmtime(time.time()-t))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
